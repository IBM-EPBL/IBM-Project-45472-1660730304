{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65daccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        #CNN - Flower Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b66776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Lib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d105744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentaton on training variable\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2eb817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation on testing variable\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0cf3182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data Augmentation on Traning Data\n",
    "xtrain = train_datagen.flow_from_directory('/home/anonimouz/Music/dataset/Training', target_size = (64,64), class_mode = 'categorical', batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056e110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data AUgmentation on Testing Data\n",
    "xtest = test_datagen.flow_from_directory('/home/anonimouz/Music/dataset/Testing', target_size = (64,64), class_mode = 'categorical', batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301c0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN MODEL TRAINING\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1f54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building CNN Block\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3),activation = 'relu',input_shape = (64,64,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(150,activation = 'relu'))\n",
    "model.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11ec8c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling The Model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c53d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Tuning Library\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a31fb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',patience = 5)\n",
    "lr = ReduceLROnPlateau(monitor='val_accuracy',factor=0.5,min_lr=0.00001)\n",
    "callback = [early_stop,lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49363be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46018/1288530072.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(xtrain,steps_per_epoch = len(xtrain),epochs=100,callbacks=callback,validation_data=xtest,validation_steps=len(xtest))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 19s 428ms/step - loss: 1.5326 - accuracy: 0.3938 - val_loss: 1.1711 - val_accuracy: 0.5332 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 18s 419ms/step - loss: 1.1019 - accuracy: 0.5420 - val_loss: 1.1625 - val_accuracy: 0.5402 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 1.0178 - accuracy: 0.5979 - val_loss: 1.0305 - val_accuracy: 0.6104 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.9452 - accuracy: 0.6324 - val_loss: 0.9345 - val_accuracy: 0.6479 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 18s 420ms/step - loss: 0.8813 - accuracy: 0.6604 - val_loss: 0.9314 - val_accuracy: 0.6588 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 18s 420ms/step - loss: 0.8410 - accuracy: 0.6817 - val_loss: 0.8008 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 18s 419ms/step - loss: 0.7986 - accuracy: 0.7019 - val_loss: 0.7124 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 20s 452ms/step - loss: 0.7729 - accuracy: 0.7093 - val_loss: 0.6667 - val_accuracy: 0.7596 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 19s 444ms/step - loss: 0.7335 - accuracy: 0.7264 - val_loss: 0.6949 - val_accuracy: 0.7334 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 19s 440ms/step - loss: 0.7087 - accuracy: 0.7366 - val_loss: 0.7649 - val_accuracy: 0.7044 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 19s 435ms/step - loss: 0.7083 - accuracy: 0.7350 - val_loss: 0.6139 - val_accuracy: 0.7684 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 19s 440ms/step - loss: 0.6247 - accuracy: 0.7635 - val_loss: 0.6764 - val_accuracy: 0.7464 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 19s 436ms/step - loss: 0.6263 - accuracy: 0.7612 - val_loss: 0.5053 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 19s 439ms/step - loss: 0.6210 - accuracy: 0.7693 - val_loss: 0.6114 - val_accuracy: 0.7725 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 19s 441ms/step - loss: 0.6084 - accuracy: 0.7739 - val_loss: 0.5817 - val_accuracy: 0.7790 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 20s 450ms/step - loss: 0.5603 - accuracy: 0.7913 - val_loss: 0.5009 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 19s 436ms/step - loss: 0.5071 - accuracy: 0.8087 - val_loss: 0.4351 - val_accuracy: 0.8376 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 19s 441ms/step - loss: 0.4886 - accuracy: 0.8198 - val_loss: 0.4321 - val_accuracy: 0.8304 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 20s 463ms/step - loss: 0.5104 - accuracy: 0.8096 - val_loss: 0.4484 - val_accuracy: 0.8265 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 19s 441ms/step - loss: 0.4694 - accuracy: 0.8293 - val_loss: 0.4277 - val_accuracy: 0.8416 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 19s 441ms/step - loss: 0.4154 - accuracy: 0.8420 - val_loss: 0.4512 - val_accuracy: 0.8344 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 19s 437ms/step - loss: 0.4106 - accuracy: 0.8504 - val_loss: 0.3722 - val_accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 19s 435ms/step - loss: 0.3830 - accuracy: 0.8612 - val_loss: 0.2783 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 19s 446ms/step - loss: 0.3762 - accuracy: 0.8640 - val_loss: 0.3108 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 19s 433ms/step - loss: 0.3757 - accuracy: 0.8673 - val_loss: 0.2447 - val_accuracy: 0.9171 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 19s 432ms/step - loss: 0.3506 - accuracy: 0.8726 - val_loss: 0.3147 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 19s 437ms/step - loss: 0.3399 - accuracy: 0.8782 - val_loss: 0.3562 - val_accuracy: 0.8698 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 19s 436ms/step - loss: 0.3253 - accuracy: 0.8858 - val_loss: 0.2506 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 19s 433ms/step - loss: 0.2923 - accuracy: 0.8967 - val_loss: 0.2348 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 19s 430ms/step - loss: 0.2747 - accuracy: 0.9069 - val_loss: 0.1939 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 19s 434ms/step - loss: 0.2750 - accuracy: 0.9053 - val_loss: 0.3478 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 19s 435ms/step - loss: 0.2659 - accuracy: 0.9085 - val_loss: 0.1680 - val_accuracy: 0.9446 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 19s 440ms/step - loss: 0.2313 - accuracy: 0.9233 - val_loss: 0.1449 - val_accuracy: 0.9541 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 19s 433ms/step - loss: 0.2399 - accuracy: 0.9127 - val_loss: 0.1561 - val_accuracy: 0.9534 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 19s 438ms/step - loss: 0.2038 - accuracy: 0.9277 - val_loss: 0.1347 - val_accuracy: 0.9541 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 19s 437ms/step - loss: 0.1935 - accuracy: 0.9331 - val_loss: 0.1674 - val_accuracy: 0.9416 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 19s 437ms/step - loss: 0.2363 - accuracy: 0.9185 - val_loss: 0.1927 - val_accuracy: 0.9277 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 19s 427ms/step - loss: 0.1822 - accuracy: 0.9375 - val_loss: 0.1593 - val_accuracy: 0.9412 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3d332dfd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Training Modified\n",
    "model.fit_generator(xtrain,steps_per_epoch = len(xtrain),epochs=100,callbacks=callback,validation_data=xtest,validation_steps=len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21e31d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sunflower'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing The Model\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img('/home/anonimouz/Music/dataset/Training/sunflower/678714585_addc9aaaef.jpg', target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "pred = np.argmax(model.predict(x))\n",
    "op = ['Daisy','Dandelion','Rose','Sunflower','Tulip']\n",
    "op[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23ec85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
