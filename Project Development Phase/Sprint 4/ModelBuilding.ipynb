{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08a701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "#Creating the dimensions for the ROI...\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 150\n",
    "ROI_left = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356a5950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31101 images belonging to 26 classes.\n",
      "Found 730 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = r'/home/anonimouz/Documents/SignLanguage/gesture/train'\n",
    "test_path = r'/home/anonimouz/Documents/SignLanguage/gesture/test'\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "202562ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imgs, labels = next(train_batches)\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfcc0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(26,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805162b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                294976    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 416,410\n",
      "Trainable params: 416,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616808b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f70068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3111/3111 [==============================] - 76s 24ms/step - loss: 0.1676 - accuracy: 0.9638 - val_loss: 0.0613 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "3111/3111 [==============================] - 73s 24ms/step - loss: 0.0426 - accuracy: 0.9929 - val_loss: 1.6384e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "3111/3111 [==============================] - 76s 24ms/step - loss: 0.0218 - accuracy: 0.9966 - val_loss: 1.1261e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "3111/3111 [==============================] - 75s 24ms/step - loss: 6.0457e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9959 - lr: 2.0000e-04\n",
      "Epoch 5/10\n",
      "3111/3111 [==============================] - 73s 23ms/step - loss: 3.1256e-04 - accuracy: 0.9999 - val_loss: 1.2166e-07 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "3111/3111 [==============================] - 73s 23ms/step - loss: 3.4253e-07 - accuracy: 1.0000 - val_loss: 4.2295e-08 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "3111/3111 [==============================] - 74s 24ms/step - loss: 1.0593e-07 - accuracy: 1.0000 - val_loss: 9.9613e-09 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "3111/3111 [==============================] - 72s 23ms/step - loss: 2.5110e-08 - accuracy: 1.0000 - val_loss: 9.7980e-10 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "3111/3111 [==============================] - 73s 23ms/step - loss: 6.1941e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "3111/3111 [==============================] - 75s 24ms/step - loss: 1.7900e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd96e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(test_batches) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc17ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.0; accuracy of 100.0%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "923ded32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ASLmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aed83678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on a small set of test data--\n",
      "\n",
      "G   F   Q   X   D   A   T   U   W   V   "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "G   F   Q   X   D   A   T   U   W   V   "
     ]
    }
   ],
   "source": [
    "\n",
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'I',10:'J',11:'K',12:'L',13:'M',14:'N',15:'O',16:'P',17:'Q',18:'R',19:'S',20:'T',21:'U',22:'V',23:'W',24:'X',25:'Y',26:'Z'}\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b056255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
